{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"查看数据\"\"\" \n",
    "import pandas as pd\n",
    "titanic = pd.read_csv('train.csv')\n",
    "# titanic.head(3)\n",
    "print(titanic.describe())\n",
    "print(titanic.info())\n",
    "\n",
    "# 年龄数据缺失较多\n",
    "# Sex、Embarked、Name等属性都是object类型，要将其转化为机器学习能处理的类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female']\n",
      "count     889\n",
      "unique      3\n",
      "top         S\n",
      "freq      644\n",
      "Name: Embarked, dtype: object\n",
      "['S' 'C' 'Q' nan]\n",
      "Embarked\n",
      "C    168\n",
      "Q     77\n",
      "S    644\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"数据预处理\"\"\"\n",
    "# 用平均值填补缺失值\n",
    "titanic['Age'] = titanic['Age'].fillna(titanic['Age'].mean())\n",
    "\n",
    "print(titanic['Sex'].unique())\n",
    "# titanic.loc[0]表示第0行的样本\n",
    "# titanic.loc[0, 'PassengerId']表示行为0，列为PassengerId的值\n",
    "titanic.loc[titanic['Sex'] == 'male', 'Sex'] = 0\n",
    "titanic.loc[titanic['Sex'] == 'female', 'Sex'] = 1\n",
    "\n",
    "print(titanic['Embarked'].describe())\n",
    "print(titanic['Embarked'].unique())\n",
    "embark_count=titanic.groupby(['Embarked']).size()\n",
    "print(embark_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "titanic['Embarked'] = titanic['Embarked'].fillna('S')\n",
    "titanic.loc[titanic['Embarked'] == 'S', 'Embarked'] = 0\n",
    "titanic.loc[titanic['Embarked'] == 'C', 'Embarked'] = 1\n",
    "titanic.loc[titanic['Embarked'] == 'Q', 'Embarked'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**特征工程**\n",
    "\n",
    "从给的数据里提炼出新的特征\n",
    "提炼的3个新特征为FamilySize：SibSp和Parch的人数相加，看看是否家庭人数越多获救几率越大；NameLength：名字长度，外国名字越长地位越高；Title：在Name里提取的，类似Mr、Mrs、Dr表示性别职业\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    0  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    1  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry    0  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin  Embarked  \n",
       "0         A/5 21171   7.2500   NaN         0  \n",
       "1          PC 17599  71.2833   C85         1  \n",
       "2  STON/O2. 3101282   7.9250   NaN         0  \n",
       "3            113803  53.1000  C123         0  \n",
       "4            373450   8.0500   NaN         0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     517\n",
      "2     182\n",
      "3     125\n",
      "4      40\n",
      "5       7\n",
      "6       6\n",
      "8       2\n",
      "7       2\n",
      "9       2\n",
      "16      1\n",
      "10      1\n",
      "11      1\n",
      "12      1\n",
      "13      1\n",
      "14      1\n",
      "15      1\n",
      "17      1\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 提炼新特征\n",
    "titanic['FamilySize'] = titanic['SibSp'] + titanic['Parch']\n",
    "titanic['NameLength'] = titanic['Name'].apply(lambda x: len(x))\n",
    "import re\n",
    "import pandas as pd\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    \n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return ''\n",
    "titles = titanic['Name'].apply(get_title)\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 8, \"Mlle\": 9,\n",
    "                 \"Mme\": 10, \"Don\": 11, \"Lady\": 12, \"Countess\": 13, \"Jonkheer\": 14, \"Sir\": 15, \"Capt\": 16, \"Ms\": 17\n",
    "                 }\n",
    "for k, v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "print(pd.value_counts(titles))\n",
    "titanic['Title'] = titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>NameLength</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    0  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    1  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry    0  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin  Embarked  FamilySize  NameLength Title  \n",
       "0         A/5 21171   7.2500   NaN         0           1          23     1  \n",
       "1          PC 17599  71.2833   C85         1           1          51     3  \n",
       "2  STON/O2. 3101282   7.9250   NaN         0           0          22     2  \n",
       "3            113803  53.1000  C123         0           1          44     3  \n",
       "4            373450   8.0500   NaN         0           0          24     1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 特征选择\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \n",
    "\"FamilySize\", \"NameLength\", \"Title\"]\n",
    "selector = SelectKBest(f_classif, k=5)# 方差分析，计算方差分析（ANOVA）的F值 (组间均方 / 组内均方)，选取前5个特征\n",
    "selector.fit(titanic[predictors], titanic['Survived'])\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "#发现“Pclass”、 \"Sex\"、“Fare”、\"NameLength\"和“Title”这5个特征比较重要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7822671156004489\n"
     ]
    }
   ],
   "source": [
    "\"\"\"线性回归\"\"\"\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "# 选择特征\n",
    "predictors = ['Pclass', 'Sex', 'Fare', 'NameLength','Title']\n",
    "# 导入线性回归\n",
    "alg = LinearRegression()\n",
    "# 将样本分为3份进行交叉验证\n",
    "kf = KFold(n_splits=3, random_state=1)\n",
    "predictions = []\n",
    "for train_index, test_index in kf.split(titanic):\n",
    "#     print(test_index)\n",
    "    # 用于训练的特征数据\n",
    "    train_predictors = titanic[predictors].iloc[train_index, :]\n",
    "    # 特征数据的label(即是否获救)\n",
    "    train_target = titanic['Survived'].iloc[train_index]  # train_target = titanic['Survived'][train_index]\n",
    "    # 训练线性回归模型\n",
    "    alg.fit(train_predictors, train_target)    \n",
    "    test_predictions = alg.predict(titanic[predictors].iloc[test_index, :])\n",
    "    predictions.append(test_predictions)\n",
    "# 线性回归得到的结果是在[0,1]，转化为类别\n",
    "import numpy as np\n",
    "#因为没有shuffle\n",
    "predictions = np.concatenate(predictions, axis=0)# predictions = np.hstack(predictions)\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <= .5] = 0\n",
    "# predictions = np.where(predictions > .5, 1, 0)\n",
    "# 线性模型准确率\n",
    "accuracy = sum(predictions == titanic['Survived']) / len(predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass  Sex      Fare  NameLength Title\n",
      "0         3    0    7.2500          23     1\n",
      "1         1    1   71.2833          51     3\n",
      "2         3    1    7.9250          22     2\n",
      "3         1    1   53.1000          44     3\n",
      "4         3    0    8.0500          24     1\n",
      "5         3    0    8.4583          16     1\n",
      "6         1    0   51.8625          23     1\n",
      "7         3    0   21.0750          30     4\n",
      "8         3    1   11.1333          49     3\n",
      "9         2    1   30.0708          35     3\n",
      "10        3    1   16.7000          31     2\n",
      "11        1    1   26.5500          24     2\n",
      "12        3    0    8.0500          30     1\n",
      "13        3    0   31.2750          27     1\n",
      "14        3    1    7.8542          36     2\n",
      "15        2    1   16.0000          32     3\n",
      "16        3    0   29.1250          20     4\n",
      "17        2    0   13.0000          28     1\n",
      "18        3    1   18.0000          55     3\n",
      "19        3    1    7.2250          23     3\n",
      "20        2    0   26.0000          20     1\n",
      "21        2    0   13.0000          21     1\n",
      "22        3    1    8.0292          27     2\n",
      "23        1    0   35.5000          28     1\n",
      "24        3    1   21.0750          29     2\n",
      "25        3    1   31.3875          57     3\n",
      "26        3    0    7.2250          23     1\n",
      "27        1    0  263.0000          30     1\n",
      "28        3    1    7.8792          29     2\n",
      "29        3    0    7.8958          19     1\n",
      "..      ...  ...       ...         ...   ...\n",
      "267       3    0    7.7750          24     1\n",
      "268       1    1  153.4625          45     3\n",
      "269       1    1  135.6333          22     2\n",
      "270       1    0   31.0000          21     1\n",
      "271       3    0    0.0000          28     1\n",
      "272       2    1   19.5000          41     3\n",
      "273       1    0   29.7000          21     1\n",
      "274       3    1    7.7500          26     2\n",
      "275       1    1   77.9583          33     2\n",
      "276       3    1    7.7500          33     2\n",
      "277       2    0    0.0000          27     1\n",
      "278       3    0   29.1250          18     4\n",
      "279       3    1   20.2500          32     3\n",
      "280       3    0    7.7500          16     1\n",
      "281       3    0    7.8542          32     1\n",
      "282       3    0    9.5000          25     1\n",
      "283       3    0    8.0500          26     1\n",
      "284       1    0   26.0000          26     1\n",
      "285       3    0    8.6625          19     1\n",
      "286       3    0    9.5000          23     1\n",
      "287       3    0    7.8958          20     1\n",
      "288       2    0   13.0000          20     1\n",
      "289       3    1    7.7500          20     2\n",
      "290       1    1   78.8500          28     2\n",
      "291       1    1   91.0792          39     3\n",
      "292       2    0   12.8750          22     1\n",
      "293       3    1    8.8500          19     2\n",
      "294       3    0    7.8958          16     1\n",
      "295       1    0   27.7208          17     1\n",
      "296       3    0    7.2292          18     1\n",
      "\n",
      "[297 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pluto\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass  Sex      Fare  NameLength Title\n",
      "297       1    1  151.5500          28     2\n",
      "298       1    0   30.5000          21     1\n",
      "299       1    1  247.5208          47     3\n",
      "300       3    1    7.7500          40     2\n",
      "301       3    0   23.2500          18     1\n",
      "302       3    0    0.0000          31     1\n",
      "303       2    1   12.3500          19     2\n",
      "304       3    0    8.0500          33     1\n",
      "305       1    0  151.5500          30     4\n",
      "306       1    1  110.8833          23     2\n",
      "307       1    1  108.9000          82     3\n",
      "308       2    0   24.0000          19     1\n",
      "309       1    1   56.9292          30     2\n",
      "310       1    1   83.1583          30     2\n",
      "311       1    1  262.3750          26     2\n",
      "312       2    1   26.0000          37     3\n",
      "313       3    0    7.8958          22     1\n",
      "314       2    0   26.2500          18     1\n",
      "315       3    1    7.8542          31     2\n",
      "316       2    1   26.0000          35     3\n",
      "317       2    0   14.0000          20     5\n",
      "318       1    1  164.8667          24     2\n",
      "319       1    1  134.5000          56     3\n",
      "320       3    0    7.2500          18     1\n",
      "321       3    0    7.8958          16     1\n",
      "322       2    1   12.3500          25     2\n",
      "323       2    1   29.0000          51     3\n",
      "324       3    0   69.5500          24     1\n",
      "325       1    1  135.6333          24     2\n",
      "326       3    0    6.2375          25     1\n",
      "..      ...  ...       ...         ...   ...\n",
      "564       3    1    8.0500          30     2\n",
      "565       3    0   24.1500          20     1\n",
      "566       3    0    7.8958          20     1\n",
      "567       3    1   21.0750          43     3\n",
      "568       3    0    7.2292          19     1\n",
      "569       3    0    7.8542          17     1\n",
      "570       2    0   10.5000          18     1\n",
      "571       1    1   51.4792          45     3\n",
      "572       1    0   26.3875          32     1\n",
      "573       3    1    7.7500          17     2\n",
      "574       3    0    8.0500          28     1\n",
      "575       3    0   14.5000          20     1\n",
      "576       2    1   13.0000          20     2\n",
      "577       1    1   55.9000          41     3\n",
      "578       3    1   14.4583          32     3\n",
      "579       3    0    7.9250          19     1\n",
      "580       2    1   30.0000          27     2\n",
      "581       1    1  110.8833          52     3\n",
      "582       2    0   26.0000          26     1\n",
      "583       1    0   40.1250          19     1\n",
      "584       3    0    8.7125          19     1\n",
      "585       1    1   79.6500          19     2\n",
      "586       2    0   15.0000          23     1\n",
      "587       1    0   79.2000          32     1\n",
      "588       3    0    8.0500          21     1\n",
      "589       3    0    8.0500          19     1\n",
      "590       3    0    7.1250          20     1\n",
      "591       1    1   78.2667          47     3\n",
      "592       3    0    7.2500          26     1\n",
      "593       3    1    7.7500          18     2\n",
      "\n",
      "[297 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pluto\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass  Sex      Fare  NameLength Title\n",
      "594       2    0   26.0000          23     1\n",
      "595       3    0   24.1500          27     1\n",
      "596       2    1   33.0000          26     2\n",
      "597       3    0    0.0000          19     1\n",
      "598       3    0    7.2250          17     1\n",
      "599       1    0   56.9292          44    15\n",
      "600       2    1   27.0000          51     3\n",
      "601       3    0    7.8958          20     1\n",
      "602       1    0   42.4000          25     1\n",
      "603       3    0    8.0500          25     1\n",
      "604       1    0   26.5500          31     1\n",
      "605       3    0   15.5500          29     1\n",
      "606       3    0    7.8958          17     1\n",
      "607       1    0   30.5000          27     1\n",
      "608       2    1   41.5792          53     3\n",
      "609       1    1  153.4625          25     2\n",
      "610       3    1   31.2750          57     3\n",
      "611       3    0    7.0500          21     1\n",
      "612       3    1   15.5000          27     2\n",
      "613       3    0    7.7500          16     1\n",
      "614       3    0    8.0500          31     1\n",
      "615       2    1   65.0000          19     2\n",
      "616       3    0   14.4000          25     1\n",
      "617       3    1   16.1000          47     3\n",
      "618       2    1   39.0000          27     2\n",
      "619       2    0   10.5000          19     1\n",
      "620       3    0   14.4542          19     1\n",
      "621       1    0   52.5542          28     1\n",
      "622       3    0   15.7417          16     1\n",
      "623       3    0    7.8542          27     1\n",
      "..      ...  ...       ...         ...   ...\n",
      "861       2    0   11.5000          27     1\n",
      "862       1    1   25.9292          51     3\n",
      "863       3    1   69.5500          33     2\n",
      "864       2    0   13.0000          22     1\n",
      "865       2    1   13.0000          24     3\n",
      "866       2    1   13.8583          28     2\n",
      "867       1    0   50.4958          36     1\n",
      "868       3    0    9.5000          27     1\n",
      "869       3    0   11.1333          31     4\n",
      "870       3    0    7.8958          17     1\n",
      "871       1    1   52.5542          48     3\n",
      "872       1    0    5.0000          24     1\n",
      "873       3    0    9.0000          27     1\n",
      "874       2    1   24.0000          37     3\n",
      "875       3    1    7.2250          32     2\n",
      "876       3    0    9.8458          29     1\n",
      "877       3    0    7.8958          20     1\n",
      "878       3    0    7.8958          18     1\n",
      "879       1    1   83.1583          45     3\n",
      "880       2    1   26.0000          44     3\n",
      "881       3    0    7.8958          18     1\n",
      "882       3    1   10.5167          28     2\n",
      "883       2    0   10.5000          29     1\n",
      "884       3    0    7.0500          22     1\n",
      "885       3    1   29.1250          36     3\n",
      "886       2    0   13.0000          21     6\n",
      "887       1    1   30.0000          28     2\n",
      "888       3    1   23.4500          40     2\n",
      "889       1    0   30.0000          21     1\n",
      "890       3    0    7.7500          19     1\n",
      "\n",
      "[297 rows x 5 columns]\n",
      "0.7037037037037037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pluto\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SVM\"\"\"\n",
    "from sklearn.svm import SVC\n",
    "# 选择特征\n",
    "predictors = ['Pclass', 'Sex', 'Fare', 'NameLength','Title']\n",
    "svm_clf = SVC()\n",
    "kf = KFold(n_splits=3, random_state=1)\n",
    "predictions = []\n",
    "for train_index, test_index in kf.split(titanic):\n",
    "    print(titanic[predictors].iloc[test_index, :])\n",
    "    # 用于训练的特征数据\n",
    "    train_predictors = titanic[predictors].iloc[train_index, :]\n",
    "    # 特征数据的label(即是否获救)\n",
    "    train_target = titanic['Survived'].iloc[train_index]  # train_target = titanic['Survived'][train_index]\n",
    "    # 训练线性回归模型\n",
    "    svm_clf.fit(train_predictors, train_target)    \n",
    "    test_predictions = svm_clf.predict(titanic[predictors].iloc[test_index, :])\n",
    "    predictions.append(test_predictions)\n",
    "# 线性回归得到的结果是在[0,1]，转化为类别\n",
    "import numpy as np\n",
    "#因为没有shuffle\n",
    "predictions = np.concatenate(predictions, axis=0)# predictions = np.hstack(predictions)\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <= .5] = 0\n",
    "# predictions = np.where(predictions > .5, 1, 0)\n",
    "# 线性模型准确率\n",
    "accuracy = sum(predictions == titanic['Survived']) / len(predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pluto\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7856341189674523\n"
     ]
    }
   ],
   "source": [
    "\"\"\"随机森林\"\"\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# 选择特征\n",
    "predictors = ['Pclass', 'Sex', 'Fare', 'NameLength','Title']\n",
    "RFC = RandomForestClassifier()\n",
    "kf = KFold(n_splits=3, random_state=1)\n",
    "predictions = []\n",
    "for train_index, test_index in kf.split(titanic):\n",
    "#     print(test_index)\n",
    "    # 用于训练的特征数据\n",
    "    train_predictors = titanic[predictors].iloc[train_index, :]\n",
    "    # 特征数据的label(即是否获救)\n",
    "    train_target = titanic['Survived'].iloc[train_index]  # train_target = titanic['Survived'][train_index]\n",
    "    # 训练线性回归模型\n",
    "    RFC.fit(train_predictors, train_target)    \n",
    "    test_predictions = RFC.predict(titanic[predictors].iloc[test_index, :])\n",
    "    predictions.append(test_predictions)\n",
    "# 线性回归得到的结果是在[0,1]，转化为类别\n",
    "import numpy as np\n",
    "#因为没有shuffle\n",
    "predictions = np.concatenate(predictions, axis=0)# predictions = np.hstack(predictions)\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <= .5] = 0\n",
    "# predictions = np.where(predictions > .5, 1, 0)\n",
    "# 线性模型准确率\n",
    "accuracy = sum(predictions == titanic['Survived']) / len(predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 1 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1\n",
      " 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0\n",
      " 0 1 0 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 1 0 1 0 1 0 0 0\n",
      " 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 0 1\n",
      " 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1\n",
      " 0 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0\n",
      " 0 0 1 0 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 0\n",
      " 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0\n",
      " 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0\n",
      " 0 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 1 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1\n",
      " 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     240\n",
      "2      79\n",
      "3      72\n",
      "4      21\n",
      "8       2\n",
      "6       2\n",
      "17      1\n",
      "5       1\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 提炼新特征\n",
    "test['FamilySize'] = test['SibSp'] + test['Parch']\n",
    "test['NameLength'] = test['Name'].apply(lambda x: len(x))\n",
    "import re\n",
    "import pandas as pd\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    \n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return ''\n",
    "titles = test['Name'].apply(get_title)\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 8, \"Mlle\": 9,\n",
    "                 \"Mme\": 10, \"Don\": 11, \"Lady\": 12, \"Countess\": 13, \"Jonkheer\": 14, \"Sir\": 15, \"Capt\": 16, \"Ms\": 17\n",
    "                 }\n",
    "\n",
    "for k, v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "print(pd.value_counts(titles))\n",
    "test['Title'] = titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female']\n",
      "count     418\n",
      "unique      3\n",
      "top         S\n",
      "freq      270\n",
      "Name: Embarked, dtype: object\n",
      "['Q' 'S' 'C']\n",
      "Embarked\n",
      "C    102\n",
      "Q     46\n",
      "S    270\n",
      "dtype: int64\n",
      "count    418.000000\n",
      "mean       0.464115\n",
      "std        0.685516\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        1.000000\n",
      "max        2.000000\n",
      "Name: Embarked, dtype: float64\n",
      "[2 0 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"数据预处理\"\"\"\n",
    "# 用平均值填补缺失值\n",
    "test['Age'] = test['Age'].fillna(test['Age'].mean())\n",
    "\n",
    "print(test['Sex'].unique())\n",
    "# titanic.loc[0]表示第0行的样本\n",
    "# titanic.loc[0, 'PassengerId']表示行为0，列为PassengerId的值\n",
    "test.loc[test['Sex'] == 'male', 'Sex'] = 0\n",
    "test.loc[test['Sex'] == 'female', 'Sex'] = 1\n",
    "\n",
    "print(test['Embarked'].describe())\n",
    "print(test['Embarked'].unique())\n",
    "embark_count=test.groupby(['Embarked']).size()\n",
    "print(embark_count)\n",
    "\n",
    "\n",
    "test['Embarked'] = test['Embarked'].fillna('S')\n",
    "test.loc[test['Embarked'] == 'S', 'Embarked'] = 0\n",
    "test.loc[test['Embarked'] == 'C', 'Embarked'] = 1\n",
    "test.loc[test['Embarked'] == 'Q', 'Embarked'] = 2\n",
    "\n",
    "print(test['Embarked'].describe())\n",
    "print(test['Embarked'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-998e6216a955>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpredictors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Pclass'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sex'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Fare'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NameLength'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'max_row'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtest_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# print(test[predictors].iloc[:, :])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \"\"\"\n\u001b[1;32m--> 545\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimators_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    357\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[0;32m    393\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 542\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "predictors = ['Pclass', 'Sex', 'Fare', 'NameLength','Title']\n",
    "pd.set_option('max_row',500)\n",
    "test_predictions = RFC.predict(test[predictors].iloc[:, :])\n",
    "# print(test[predictors].iloc[:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
